{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.13"
    },
    "toc": {
      "colors": {
        "hover_highlight": "#DAA520",
        "navigate_num": "#000000",
        "navigate_text": "#333333",
        "running_highlight": "#FF0000",
        "selected_highlight": "#FFD700",
        "sidebar_border": "#EEEEEE",
        "wrapper_background": "#FFFFFF"
      },
      "moveMenuLeft": true,
      "nav_menu": {
        "height": "12px",
        "width": "252px"
      },
      "navigate_menu": true,
      "number_sections": false,
      "sideBar": true,
      "threshold": 4,
      "toc_cell": false,
      "toc_section_display": "block",
      "toc_window_display": false,
      "widenNotebook": false
    },
    "colab": {
      "name": "TP2-2021.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/securitylab-repository/TPS-IA/blob/master/TP2_2021.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zXk9XG5rJWk"
      },
      "source": [
        "# Predicting the progression of diabetes using linear regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkymYOi0rJWq"
      },
      "source": [
        "The **diabetes** data set described in lecture can be obtained as a single file, [diabetes-data.csv](https://raw.githubusercontent.com/securitylab-repository/TPS-IA/master/diabetes-data.csv), from the course website. We obtained it at https://web.stanford.edu/~hastie/Papers/LARS/diabetes.data. For some background information on the data, see this seminal paper:\n",
        "\n",
        "Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\n",
        "\n",
        "Before you start on this notebook, install `diabetes-data.csv` in the same directory. We will walk through some of the examples from lecture as well as giving you some problems to solve.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "hsv4oIwQrJWr"
      },
      "source": [
        "# Standard includes\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "# Routines for linear regression\n",
        "from sklearn import linear_model\n",
        "from sklearn.metrics import mean_squared_error\n",
        "# Set label size for plots\n",
        "matplotlib.rc('xtick', labelsize=14) \n",
        "matplotlib.rc('ytick', labelsize=14)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qO2xfo3rJWr"
      },
      "source": [
        "This next snippet of code loads in the diabetes data. There are 442 data points, each with 10 predictor variables (which we'll denote `x`) and one response variable (which we'll denote `y`).\n",
        "\n",
        "Make sure the file `'diabetes-data.csv'` is in the same directory as this notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUCp6H0zrJWr"
      },
      "source": [
        "data = np.genfromtxt('diabetes-data.csv', delimiter=',')\n",
        "features = ['age', 'sex', 'body mass index', 'blood pressure', \n",
        "            'serum1', 'serum2', 'serum3', 'serum4', 'serum5', 'serum6']\n",
        "x = data[:,0:10] # predictors\n",
        "y = data[:,10] # response variable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zqrCoTbrJWs"
      },
      "source": [
        "## 1. Predict `y` without using `x`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixhssBynrJWs"
      },
      "source": [
        "If we want to predict `y` without knowledge of `x`, what value would be predict? The <font color=\"magenta\">mean</font> value of `y`.\n",
        "\n",
        "In this case, the mean squared error (MSE) associated with the prediction is simply the variance of `y`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7rUa_WKrJWs"
      },
      "source": [
        "print \"Prediction: \", np.mean(y)\n",
        "print \"Mean squared error: \", np.var(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhcqWIJxrJWs"
      },
      "source": [
        "## 2. Predict `y` using `x`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVnS3iBMrJWt"
      },
      "source": [
        "To fit a linear regression model, we could directly use the formula we saw in lecture. To make things even easier, this is already implemented in `sklearn.linear_model.LinearRegression()`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6u3_z7KrJWt"
      },
      "source": [
        "The following code takes `x` and `y`, along with the index `f = 3` of a single feature and fits a linear regressor to `(x[f],y)`. It then plots the data along with the resulting line."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QA_RFQOHrJWt"
      },
      "source": [
        "data = np.genfromtxt('diabetes-data.csv', delimiter=',')\n",
        "features = ['age', 'sex', 'body mass index', 'blood pressure', \n",
        "            'serum1', 'serum2', 'serum3', 'serum4', 'serum5', 'serum6']\n",
        "x = data[:,0:10] # predictors\n",
        "y = data[:,10] # response variable\n",
        "regr = linear_model.LinearRegression()\n",
        "x1 = x[:,[3]]\n",
        "regr.fit(x1, y)\n",
        "# Make predictions using the model. A tric  to plot the line\n",
        "y_pred = regr.predict(x1)\n",
        "# Plot data points as well as predictions\n",
        "plt.plot(x1, y, 'bo')\n",
        "plt.plot(x1, y_pred, 'r-', linewidth=3)\n",
        "plt.xlabel(features[3], fontsize=14)\n",
        "plt.ylabel('Progression of disease', fontsize=14)\n",
        "plt.show()\n",
        "print \"w = \", regr.coef_\n",
        "print \"b = \", regr.intercept_\n",
        "\n",
        "print \"Score: \" , regr.score(x1, y)\n",
        "print \"Mean squared error: \", mean_squared_error(y, regr.predict(x1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ABjt7uKrJWt"
      },
      "source": [
        "> Compare the results with those obtained in question `2.`\n",
        "\n",
        "> Give code that makes a prediction for the values `84` and `83` of the `blood preddure` feature \n",
        "\n",
        "> Let's try this with feature #2 (body mass index).\n",
        "\n",
        "> For you to try: Feature #2 ('body mass index') is the single feature that yields the lowest mean squared error. Which feature is the second best?\n",
        "\n",
        "> What is the problem with the approach used here to compute the `score` and `MSE`.\n",
        "  - propose a solution to this issue by using the function below "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQ64PRWorJWw"
      },
      "source": [
        "def split_data(n_train):\n",
        "    if (n_train < 0) or (n_train > 442):\n",
        "        print \"Invalid number of training points\"\n",
        "        return\n",
        "    np.random.seed(0)\n",
        "    perm = np.random.permutation(442)\n",
        "    training_indices = perm[range(0,n_train)]\n",
        "    test_indices = perm[range(n_train,442)]\n",
        "    trainx = x[training_indices,:]\n",
        "    trainy = y[training_indices]\n",
        "    testx = x[test_indices,:]\n",
        "    testy = y[test_indices]\n",
        "    return trainx, trainy, testx, testy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OL4m3fQn84PH"
      },
      "source": [
        "This function `split_data`  partitions the data set into separate training and test sets. It is invoked as follows:\n",
        "\n",
        "* `trainx, trainy, testx, testy = split_data(n_train)`\n",
        "\n",
        "Here:\n",
        "* `n_train` is the desired number of training points\n",
        "* `trainx` and `trainy` are the training points and response values\n",
        "* `testx` and `testy` are the test points and response values\n",
        "\n",
        "The split is done randomly, but the random seed is fixed, and thus the same split is produced if the procedure is called repeatedly with the same `n_train` parameter.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ju2XWwJ4rJWu"
      },
      "source": [
        "### You can use this space to figure out the second-best feature"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMFw4w-47v72"
      },
      "source": [
        "> Extend this solution to predict `y` using a specified subset of features from `x`\n",
        "\n",
        "> "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54GtOnHE8WSM"
      },
      "source": [
        "### You can use this space to figure out the extension"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KBIeec__TFC"
      },
      "source": [
        "> Is the data normalized ?\n",
        " - if not proceed to the *normalization*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1hITUOh_bjI"
      },
      "source": [
        "### You can use this space to figure out the normalization of the data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGsgQETJ910L"
      },
      "source": [
        "> Imporve you linear regression algorithm by `regularizing` it. Use for this purpose `sklearn.linear_model.RidgeCV` and/or `sklearn.linear_model.Lasso` algorithms.\n",
        "  - Compare the results with simple linear regression algorithm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmezhDbQ-_5V"
      },
      "source": [
        "### You can use this space to figure out the regularization"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}